# -*- coding: utf-8 -*-
"""Breast Cancer Regresión Logistica

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i8YMoYi5uxNWxnzel7T5i8Gyipb_Y5L4

# Breast Cancer
La aspiración con aguja fina, Fine-needle aspiration (FNA), es un procedimiento de diagnóstico que se utiliza para investigar masas (tumores). Los Features fueron calculados a partir de una imagen digitalizada de una FNA y describen las características de los núcleos celulares presentes en la imagen.

Información de Variables:

1. ID number: Número de identificación asignado a cada muestra en el dataset.
2. Diagnosis: (M = malignant, B = benign), es el Target.
3. 10 características numéricas por cada célula
- Radius: promedio de las distancias desde el centro a puntos del perímetro, el cual representa el tamaño de las células.
- Texture: Desviación estandar de valores en la escala de grises.
- Perimeter: Longitud del perímetro del nucleo celular.
- Area: del núcleo celular
- Smoothness: variación local en longitud de radio
- Compactness: perímetro^2/area - 1.0: Mide qué tan compactas son las células.
- Concavity: severidad de las porciones cóncavas del contorno.
- Concave points: Número de porciones cóncavas del contorno.
- Symmetry: simetría del núcleo.
- Fractal dimension: Describe la complejidad de la forma del núcleo celular

Puede encontrar el dataset en el siguiente repositorio: [Breast Cancer Wisconsin](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)

## 1. Descarga y limpiesa del Dataset
"""

# Importación principales librerías

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Importación Dataset
df = pd.read_csv('/content/data.csv')

df.head(10) # Variable diagnosis es el target

# Verificación del dataset
df.info()

# No hay variables nulas y todas son variables numéricas.

"""### Analizando el target"""

# Analizando el target

sns.countplot(x='diagnosis', data=df, palette='hls')
# No se observa un desvalanceo

# Contando los valores la variable objetivo

df['diagnosis'].value_counts()

# B: Benigno, M: Maligno

# Realizando el cambio B->1, M->0
df['diagnosis'] = df['diagnosis'].replace({'M': 0, 'B': 1})

# Validando
df['diagnosis'].value_counts()

# Porcentaje de tumores benignos
df.diagnosis.mean()

"""### Analizando variables"""

# Exploración de variables

df.groupby('diagnosis').mean()

"""## 2. Muestreo"""

from sklearn.model_selection import train_test_split

train, test = train_test_split(df,
                               stratify = df['diagnosis'],
                               train_size = 0.7,
                               random_state = 123)

# Validación

print(f'Tamaño del total de datos: {len(df)}')
print(f'Tamaño de train: {len(train)}')
print(f'Tamaño de test: {len(test)}')

"""# 3. Tratamiento de variables"""

# Variables numéricas
numerical_features = list(set(df) - set(['id', 'Unnamed: 32', 'diagnosis']))

# Verificando
numerical_features

df_univariate = train[numerical_features].describe().transpose()
df_univariate.reset_index(inplace = True)

df_univariate.rename(columns = {'index':'feature',
                       '25%':'Q1',
                       '50%':'median',
                       '75%':'Q3'}, inplace= True)
df_univariate

train[numerical_features]

# Creando y calculando los intervalos RIC(rango intercuartílico)

df_univariate['ric']     = df_univariate['Q3'] - df_univariate['Q1']
df_univariate['min_ric'] = df_univariate['Q1'] - 1.5*df_univariate['ric']
df_univariate['max_ric'] = df_univariate['Q3'] + 1.5*df_univariate['ric']

df_univariate.head()

# Tratamiento de outliers
for col in df_univariate.feature.tolist():
  desc = df_univariate.loc[df_univariate.feature == col]

  # Definiendo ímites
  lower_limit = desc.min_ric.values[0]
  upper_limit = desc.max_ric.values[0]

  # Ese dato lo utilizamos:
  train[col + '_tric'] = train[col].apply(lambda x: lower_limit if x <= lower_limit else
                                                    upper_limit if x >= upper_limit else
                                                    x)

  # Aplicando los límites también a test:
  test[col + '_tric']  = test[col].apply(lambda x: lower_limit if x <= lower_limit else
                                                    upper_limit if x >= upper_limit else
                                                    x)

train.head()

sns.boxplot(x = train.radius_mean)

sns.boxplot(x = train.radius_mean_tric)

def analisisNumericas(pddf, variable):

  print(" "*20,"Histograma"," "*20)
  pddf[variable].plot.hist(bins=25,figsize=(8,4))
  plt.title(f'{variable} \n',fontdict={'fontsize':16})
  plt.show()
  print("\n")
  print(" "*20,"Boxplot"," "*20)
  pddf[variable].plot.box(figsize=(8,4))
  plt.show()

for numerica in train[numerical_features]:
  print("#"*20,numerica,"#"*20)
  analisisNumericas(df, numerica)
  print("\n\n")

# Transformando a dataframe las características numéricas
df_numerical = df[numerical_features]

def analisisNumericas(pddf, variable):

  print(" "*20,"Histograma"," "*20)
  pddf[variable].plot.hist(bins=30,figsize=(8,4))
  plt.title(f'{variable} \n',fontdict={'fontsize':16})
  plt.show()
  print("\n")
  print(" "*20,"Boxplot"," "*20)
  pddf[variable].plot.box(figsize=(8,4))
  plt.show()

for numerica in df[numerical_features]:
  print("#"*20,numerica,"#"*20)
  analisisNumericas(df, numerica)
  print("\n\n")

"""## Pre-selección de variables
Haré uso del indicador GINI para encontrar las variables más importantes, para ello haré uso de la librería roc_auc_score. \
GINI = auc*2-1
"""

# Cálculo de GINI de las variables respecto al target (diagnosis)
from sklearn.metrics import roc_auc_score

dfgini = pd.DataFrame({'feature': numerical_features,
                       'gini': [roc_auc_score(train.diagnosis, train[col])*2-1 for col in numerical_features]})

dfgini

dfgini['gini_abs'] = dfgini.gini.apply(lambda x: abs(x))

dfgini.sort_values(by = 'gini_abs', ascending = False)

# Agregando a un dataframe resumen
univariate = pd.merge(df_univariate, dfgini, on = 'feature', how = 'left')
univariate.sort_values(by = 'gini_abs', ascending = False)

# Selección de variables
print('Features iniciales: ' + str(len(univariate)))
print('Features finales: ' + str(len(univariate.loc[(univariate.gini_abs >= 0.8)])))

final_features = univariate.loc[(univariate.gini_abs >= 0.8)].feature.tolist()
final_features

"""# 5. Regresión Logística"""

import statsmodels.api as sm

mod = sm.Logit(train.diagnosis,
                  sm.add_constant(train[[x for x in final_features]]))

res = mod.fit()

print(res.summary())

# Proceso de Backward
features = [x for x in final_features]
features.remove('radius_worst')

mod = sm.Logit(train.diagnosis, sm.add_constant(train[features]))
res = mod.fit()
print(res.summary())

features.remove('radius_mean')

mod = sm.Logit(train.diagnosis, sm.add_constant(train[features]))
res = mod.fit()
print(res.summary())

features.remove('area_mean')

mod = sm.Logit(train.diagnosis, sm.add_constant(train[features]))
res = mod.fit()
print(res.summary())

features.remove('perimeter_worst')

mod = sm.Logit(train.diagnosis, sm.add_constant(train[features]))
res = mod.fit()
print(res.summary())

features.remove('area_se')

mod = sm.Logit(train.diagnosis, sm.add_constant(train[features]))
res = mod.fit()
print(res.summary())

features.remove('concavity_worst')

mod = sm.Logit(train.diagnosis, sm.add_constant(train[features]))
res = mod.fit()
print(res.summary())

features.remove('concavity_mean')

mod = sm.Logit(train.diagnosis, sm.add_constant(train[features]))
res = mod.fit()
print(res.summary())

# Modelo final: Wrapper
res

plt.figure(figsize=(10, 6))
sns.heatmap(round(df[features].corr(), 2), cmap="BrBG", annot=True, vmin=-1, vmax=1)
plt.show()

# Gráfico de dispersión
plt.figure(figsize=(10, 6))
sns.scatterplot(data = df, x='concave points_worst', y='perimeter_mean', hue='diagnosis', palette='viridis', alpha=0.6)

# Etiquetas y título
plt.xlabel('concave points_worst')
plt.ylabel('perimeter_mean')

plt.show()

plt.figure(figsize=(10, 6))
sns.pairplot(data=df, hue='diagnosis', vars=['concave points_worst', 'perimeter_mean', 'concave points_mean', 'area_worst'], diag_kind='hist', palette='viridis')
plt.show()

plt.figure(figsize=(10, 6))

pairplot = sns.pairplot(data=df,
                        hue='diagnosis',
                        vars=['concave points_worst', 'perimeter_mean', 'concave points_mean', 'area_worst'],
                        diag_kind='hist',
                        palette='viridis')

# Ajustar el tamaño de los labels de los ejes
for ax in pairplot.axes.flatten():
    ax.set_xlabel(ax.get_xlabel(), fontsize=13)  # Tamaño del label del eje x
    ax.set_ylabel(ax.get_ylabel(), fontsize=13)  # Tamaño del label del eje y
    ax.tick_params(axis='both', labelsize=11)    # Tamaño de los ticks en ambos ejes

# Ajustar el tamaño de la leyenda
pairplot._legend.set_title('Diagnosis')   # Cambiar el título de la leyenda si es necesario
pairplot._legend.set_bbox_to_anchor((1, 0.5))  # Posicionar la leyenda fuera del gráfico si es necesario
for text in pairplot._legend.get_texts():
    text.set_fontsize(14)  # Tamaño de la fuente en la leyenda

output_path = 'scatter_plot.pdf'
plt.savefig(output_path, format='pdf')

plt.show()

# Ajustar la transparencia de los scatterplots
# Crear el PairGrid
g = sns.pairplot(data=df, hue='diagnosis', vars=['concave points_worst', 'perimeter_mean', 'concave points_mean', 'area_worst'], diag_kind='hist', palette='viridis')

for ax in g.axes.flatten():
    if ax is not None:
        for artist in ax.collections:
            artist.set_alpha(0.6)  # Ajusta el nivel de transparencia aquí

# Mostrar la gráfica
plt.show()

"""# 6. Performance
Las métricas más importantes en medicina son sensitivity(recall) y specificity
"""

# Usando el modelo para predecir
train_II = train.copy()
test_II = test.copy()

train_II['probability'] = res.predict(sm.add_constant(train[features]))
test_II['probability']  = res.predict(sm.add_constant(test[features]))

# M:0 Maligno, B:1 Benigno
train_II['prediction'] = train_II['probability'].apply(lambda x: 1 if x > 0.5 else 0)
test_II['prediction']  = test_II['probability'].apply(lambda x: 1 if x > 0.5 else 0)

# Sensitivity TP/(TP+FN)
from sklearn.metrics import *

print('Train Recall: %f' %(recall_score(train.diagnosis, train_II.prediction)))
print('Test Recall: %f' %(recall_score(test.diagnosis, test_II.prediction)))

# Specificity
tn, fp, fn, tp = confusion_matrix(test.diagnosis, test_II.prediction).ravel()

specificity = tn/(tn+fp)
print('Test Specificity: ', specificity)

print('Train Specificity: %f' %(recall_score(train.diagnosis, train_II.prediction)))
print('Test Specificity: %f' %(recall_score(test.diagnosis, test_II.prediction)))

# AUC del modelo
print('Train AUC: %f' %(roc_auc_score(train.diagnosis, train_II.probability)))
print('Test AUC: %f' %(roc_auc_score(test.diagnosis, test_II.probability)))

# GINI del modelo
print('TRAIN GINI: %f' %(roc_auc_score(train.diagnosis, train_II.probability)*2-1))
print('TEST GINI: %f' %(roc_auc_score(test.diagnosis, test_II.probability)*2-1))

# Accuaracy
print('Train ACCURACY: %f' %(accuracy_score(train.diagnosis, train_II.prediction)))
print('Test ACCURACY: %f' %(accuracy_score(test.diagnosis, test_II.prediction)))

# Precision
print('Train Precision: %f' %(precision_score(train.diagnosis, train_II.prediction)))
print('Test Precision: %f' %(precision_score(test.diagnosis, test_II.prediction)))

# F-1 Score
print('Train F1-score: %f' %(f1_score(train.diagnosis, train_II.prediction)))
print('Test F1-score: %f' %(f1_score(test.diagnosis, test_II.prediction)))

# Matriz de confusión
cm = confusion_matrix(test.diagnosis, test_II.prediction)

plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
plt.show()

plt.figure(figsize=(8, 6))
ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')

# Ajustar el tamaño de los labels de los ejes
ax.set_xlabel('Predicted label', fontsize=14)
ax.set_ylabel('Actual label', fontsize=14)

# Ajustar el tamaño de los ticks de los ejes
ax.tick_params(axis='x', labelsize=12)
ax.tick_params(axis='y', labelsize=12)

# Ajustar el tamaño de las anotaciones en la matriz de confusión
for text in ax.texts:
    text.set_fontsize(12)

plt.show()

"""### Curva ROC

"""



# Curva ROC
fpr_lr, tpr_lr, _ = roc_curve(test.diagnosis, test_II.probability)

# AUC
auc_lr = auc(fpr_lr, tpr_lr)
print(auc_lr)

plt.figure()
plt.plot(fpr_lr, tpr_lr, label = f'Logistic Regression (AUC = {auc_lr:.3f})') #f'...': Indica una cadena de formato (f-string)
plt.plot([0, 1], [0, 1], 'k--') # '.2f' :formato del número flotante, 2 decimales.
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='best')
plt.show()

